{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Innovative Technologien und Services\n",
    "### von Fabian Harmsen, Phillip Krumpholz, Till Waller\n",
    "### Recommenderservice mit Python\n",
    "Ziel dieser Abgabe ist es ein funktionierendes Recommenders system zu entwickeln, welches contend-based und collaborative filtering ermöglicht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Service Innovation Canvas\n",
    "Der Service Innovation Canvas ist ein Werkzeug, das Unternehmen dabei helfen soll, ihre Dienstleistungen zu innovieren und zu optimieren. Er ähnelt dem Business Innovation Canvas, hat aber ein paar spezifische Anpassungen für die Entwicklung von Dienstleistungen. Der Service Innovation Canvas besteht aus acht Feldern:\n",
    "<br>\n",
    "1. Wertversprechen: Welche Probleme oder Bedürfnisse haben die Kunden?\n",
    "2. Kundensegmente: Wer sind die Zielkunden für die Dienstleistung?\n",
    "3. Service-Orchestrator: Wie wird die Dienstleistung gestaltet und angeboten?\n",
    "4. Partner-Ökosystem: Mit welchen Geschäftspartnern kann man fehlende Ressourcen zugänglich machen?\n",
    "5. Werterbringung: Welche Aktivitäten sind notwendig um die Dienstleistung zu erbringen?\n",
    "6. Werterfassung: Welche Umsätze sind für die Dienstleistung zu erfassen und wie werden diese finanziert?\n",
    "7. Daten: Welche Daten müssen berücksichtigt werden?\n",
    "8. Technologie: Welche Technologien werden benötigt?\n",
    "\n",
    "Der Service Innovation Canvas soll dabei helfen, die verschiedenen Aspekte einer Dienstleistung systematisch zu betrachten und zu planen. Er kann auch als Ausgangspunkt für Diskussionen und Entscheidungen innerhalb eines Unternehmens dienen.\n",
    "<br>\n",
    "<br>\n",
    "#### Businessmodel\n",
    "Das von uns entworfene Empfehlungssystem wird bei einem Streaminganbieter zum Einsatz kommen, welcher bis dahin noch kein Empfehlungssystem in Verwendung hat. Nach der Implementierung des Systems wird sich der Streaminganbieter nach einer bestimmten Zeit die Zahlen seiner Zuschauer ansehen und diese mit den Zahlen zuvor vergleichen. Hierbei erwartet der Streaminganbieter eine höhere Zuschauzeit als auch eine höhere Anzahl der gestreamten Inhalte. Falls die Zahlen für das Empfehlungssystem sprechen, wird dieses beim Streaminganbieter langfristig zum Einsatz kommen.\n",
    "Als weiteren Kunden könnte unser Empfehlungssystem bei einem Spieleanbieter in der Cloud verwendet werden. Hierbei können die ausgewählten Inhalte gleichermaßen analysiert werden. Mit der Analyse der gespielten Inhalte können weitere Empfehlungen angezeigt werden, welche für die Spieler von Interesse sein können.\n",
    "<br>\n",
    "<br>\n",
    "#### Wertversprechen\n",
    "Auf der Basis von Empfehlungen und der Analyse des eigenen Konsums können neue Inhalte auf der Plattform den Zuschauern vorgeschlagen werden. Eigene Produktionen, neue oder weniger bekannte Inhalte können dadurch an Reichweite gewinnen und von den Zuschauern gezielt konsumiert werden. Des Weiteren können Bewertungen analysiert werden, damit mögliche Wünsche der Zuschauer in zukünftigen Produktionen berücksichtigt werden können.\n",
    "<br>\n",
    "<br>\n",
    "#### Kundensegmente\n",
    "Einerseits werden die Ergebnisse des Empfehlungssystems für die Masse zur Verfügung gestellt. Anhand von abgegebenen Bewertungen der Zuschauer werden Empfehlungen für die große Masse ausgesprochen. Diese kann sich die Bewertungen ansehen und sich für den Inhalt entscheiden. Andererseits werden Empfehlungen für jeden einzelnen angeboten. Diese basieren auf den bereits konsumierten Inhalten. Mit den Informationen dieser Inhalte werden Empfehlungen ausgesprochen, welche viele Ähnlichkeiten zu den gesehenen Inhalten haben.\n",
    "<br>\n",
    "<br>\n",
    "#### Service-Orchestrator\n",
    "Das Empfehlungssystem wurde im Rahmen dieser Hausarbeit mit Unterstützung einiger Bezugsquellen selbst erarbeitet. Demzufolge sind Fabian Harmsen, Philip Krumpholz und Till Waller die Eigentümer dieses entwickelten Systems. Für die Entwicklung sind sowohl physische als auch menschliche Ressourcen zum Einsatz gekommen.\n",
    "<br>\n",
    "<br>\n",
    "#### Partner-Ökosystem\n",
    "Für die weitere Entwicklung des Empfehlungsservices sind unter anderem finanzielle Ressourcen notwendig, durch beispielsweise Investoren. Damit die Anwendung sich am Markt etablieren und festigen kann, werden Kooperationen mit Streaming- und Cloud-Gaming-Dienstleistern vorgesehen. Außerdem könnten mit dem Zugriff zu intellektuellen Ressourcen Partnerbeziehungen aufgebaut werden, mit welchen die Anzahl der Absätze und die Marge erhöht werden können.\n",
    "<br>\n",
    "<br>\n",
    "#### Werterbringung\n",
    "Die Pflege und Weiterentwicklung des Empfehlungssystems ist eine der zentralen Aufgaben, damit auch in Zukunft weitere Inhalte gezielt gezeigt und konsumiert werden können. Ebenfalls ist das Verstehen und Umsetzen der Kundenbedürfnisse von zentraler Bedeutung. An den Erkenntnissen sollte man sich orientieren und diese in die weitere Entwicklung mit einfließen lassen.\n",
    "<br>\n",
    "<br>\n",
    "#### Werterfassung\n",
    "Mit dem Empfehlungssystem wird indirekt Geld erwirtschaftet, indem Zuschauer neue Inhalte vorgeschlagen werden, welche zum weiterem Konsumieren angetrieben werden sollen. Damit soll eine längere und dauerhafte Bindung zur Plattform geschaffen werden. Mit einer längeren Mitgliedschaft werden die regelmäßigen Einnahmen in Form des Abo-Modells gefestigt.\n",
    "<br>\n",
    "<br>\n",
    "#### Daten\n",
    "Zum einen werden für die Vorschläge/Empfehlungen die Daten der Bewertungen der Filme benötigt. Diese müssen ausgewertet und für zukünftige Zuschauer bereitgestellt werden, damit diese die Bewertungen sehen und beurteilen können. Zum anderen sind Metadaten der Filme erforderlich, mit diesen werden andere Filme abgeglichen. Bei einer hohen Anzahl an Ähnlichkeiten bzw. Überschneidungen von Eigenschaften werden diese Filme bei der nächsten Suche/Gelegenheit vorgeschlagen.\n",
    "<br>\n",
    "<br>\n",
    "#### Technologie\n",
    "Für die Durchführung des kompletten Empfehlungssystems ist zunächst die Hardwareinfrastruktur mit ausreichend Leistung notwendig. Des Weiteren wird die dafür zuständige Software benötigt, welche die Empfehlungen individuell berechnet und bereitstellt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports für den Recommender\n",
    "Im folgenden Abschnitt werden Bibiliotheken für den Recommender importiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1\n",
    "Im folgenden Abschnitt wird der Aufbau des contend-basted Recommenders Schritt für Schritt erläutert. Zum Abschluss werden einige Empfehlungen zu bestimmten Filmen exemplarisch ausgegeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import der CSV \"metadata\"\n",
    "Im folgenden Abschnitt importieren wir die CSV-Dateien. Hierbei ist zu erwähnen das Filme aus der metadata.csv nicht die gleichen Filme enthalten wie die ratings_small.csv. Dies liegt daran, dass die metadata.csv den aktuellen Katalog an Filmen enthält, die ratings_small.csv hingegen alle Filme die jemals auf der Plattform waren und bewertet wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('data/movies_metadata.csv', low_memory=False)\n",
    "credits = pd.read_csv('data/credits.csv', low_memory=False)\n",
    "keywords = pd.read_csv('data/keywords.csv', low_memory=False)\n",
    "rating = pd.read_csv('data/ratings_small.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content based filtering und das Problem dahinter\n",
    "Jeder Film hat eine Beschreibung welche wir im folgenden Abschnitt einmal exemplarisch zeigen. Das offensichtliche Problem hierbei ist die automatische Verarbeitung von natürlicher Sprache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0    Led by Woody, Andy's toys live happily in his ...\n1    When siblings Judy and Peter discover an encha...\n2    A family wedding reignites the ancient feud be...\n3    Cheated on, mistreated and stepped on, the wom...\n4    Just when George Banks has recovered from his ...\nName: overview, dtype: object"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head(3)\n",
    "metadata['overview'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lösung des Problems\n",
    "Um natürliche Sprache richtig zu verarbeiten, vektorizieren wir alle Wörter jeder Beschreibung. Durch die Vektorisierung der Wörter und der Bildung einer Matrix, ist es nun möglich Beschreibungen anhand der Kosinus-Ähnlichkeit (cosine similarity) zu berechnen. Somit können nun Beschreibungen miteinander verglichen werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recommender anhand von Beschreibungen\n",
    "Die Funktion getCosineMatrixDescription nimmt einen DataFrame mit Metadaten als Eingabe und gibt eine Matrix zurück. Die Funktion führt folgende Schritte aus:\n",
    "\n",
    "Die Spalte \"overview\" des DataFrames wird vektorisiert und in eine Matrix umgewandelt, indem das TfidfVectorizer-Objekt verwendet wird. Dieser Vektorisierungsvorgang besteht darin, jedes Dokument (in diesem Fall die Übersicht eines Films) in Vektorform darzustellen, indem die Häufigkeit von jedem Wort im Dokument berücksichtigt wird. Das TfidfVectorizer-Objekt verwendet außerdem die Angabe \"english\" als Stopworte, um bestimmte häufig vorkommende Wörter wie \"the\" und \"a\" zu ignorieren.\n",
    "Die Matrix, die durch die Vektorisierung der Übersichten erhalten wurde, wird dann mit der Funktion linear_kernel mit sich selbst multipliziert, um eine Matrix mit Ähnlichkeitswerten zwischen allen Dokumenten (Übersichten) zu erhalten. Diese Ähnlichkeitswerte werden als Cosinusähnlichkeit berechnet, wodurch die Ähnlichkeit zwischen zwei Dokumenten anhand des Winkels gemessen wird, der zwischen ihren Vektoren entsteht.\n",
    "Die Cosinusähnlichkeitsmatrix wird schließlich als Rückgabewert der Funktion zurückgegeben.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCosineMatrixDescription(metadata):\n",
    "    # Vektorisieren der Beschreibung\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    metadata['overview'] = metadata['overview'].fillna('')\n",
    "    tfidf_matrix = tfidf.fit_transform(metadata['overview'])\n",
    "\n",
    "    # Bildung der Matrix\n",
    "    cosine_matrix = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "    return cosine_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hilfsfunktion get_director\n",
    "Die Funktion get_director nimmt eine Liste von dictionaries als Eingabe und gibt den Namen eines Regisseurs zurück. Die Funktion führt folgende Schritte aus:\n",
    "\n",
    "Die Funktion iteriert über jedes Dictionary in der Liste.\n",
    "Wenn das Dictionary einen Eintrag mit dem Schlüssel \"job\" hat, der den Wert \"Director\" enthält, wird der Wert des Schlüssels \"name\" des Dictionarys zurückgegeben.\n",
    "Wenn kein Dictionary gefunden wird, das den Wert \"Director\" für den Schlüssel \"job\" enthält, wird der Wert np.nan (Not a Number) zurückgegeben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def get_director(x):\n",
    "        for i in x:\n",
    "            if i['job'] == 'Director':\n",
    "                return i['name']\n",
    "        return np.nan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hilfsfunktion get_list\n",
    "Die Funktion get_list nimmt eine Liste von dictionaries als Eingabe und gibt eine Liste von Namen zurück. Die Funktion führt folgende Schritte aus:\n",
    "\n",
    "Die Funktion überprüft, ob die Eingabe eine Liste ist. Wenn dies nicht der Fall ist, wird eine leere Liste zurückgegeben.\n",
    "Wenn die Eingabe eine Liste ist, wird eine neue Liste erstellt, die die Namen aller Personen enthält, die in der Eingabelisten enthalten sind. Dies wird durchgeführt, indem für jedes Dictionary in der Liste der Wert des Schlüssels \"name\" extrahiert wird.\n",
    "Wenn die neu erstellte Liste mehr als drei Elemente enthält, wird die Liste auf die ersten drei Elemente gekürzt. Andernfalls wird die gesamte Liste zurückgegeben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def get_list(x):\n",
    "        if isinstance(x, list):\n",
    "            names = [i['name'] for i in x]\n",
    "            # Prüfe auf mehr als drei Elemente, wenn mehr nimm die ersten drei, wenn weniger nimm alle\n",
    "            if len(names) > 3:\n",
    "                names = names[:3]\n",
    "            return names\n",
    "\n",
    "        # Falls keine oder unvolständige Daten gib leere Liste\n",
    "        return []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hilfsfunktion clean_data\n",
    "Die Funktion clean_data nimmt eine Liste von Namen oder einen einzelnen Namen als Eingabe und gibt eine Liste von Namen oder einen einzelnen Namen zurück, bei denen alle Buchstaben in Kleinbuchstaben umgewandelt und alle Leerzeichen entfernt wurden. Die Funktion führt folgende Schritte aus:\n",
    "\n",
    "Die Funktion überprüft, ob die Eingabe eine Liste ist. Wenn dies der Fall ist, wird eine neue Liste erstellt, die die Namen aller Personen enthält, die in der Eingabelisten enthalten sind. Dies wird durchgeführt, indem für jedes Element in der Liste die folgenden Operationen durchgeführt werden:\n",
    "Alle Buchstaben werden in Kleinbuchstaben umgewandelt, indem die str.lower-Funktion verwendet wird.\n",
    "Alle Leerzeichen werden entfernt, indem der replace-Methodenaufruf verwendet wird.\n",
    "Wenn die Eingabe keine Liste ist, wird überprüft, ob es sich um eine Zeichenkette handelt. Wenn dies der Fall ist, werden die gleichen Operationen wie in Schritt 1 durchgeführt und der bearbeitete Name wird zurückgegeben.\n",
    "Wenn die Eingabe weder eine Liste noch eine Zeichenkette ist, wird eine leere Zeichenkette zurückgegeben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def clean_data(x):\n",
    "        if isinstance(x, list):\n",
    "            return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "        else:\n",
    "            # Prüfe ob es gibt sonst leerer String\n",
    "            if isinstance(x, str):\n",
    "                return str.lower(x.replace(\" \", \"\"))\n",
    "            else:\n",
    "                return ''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Metadaten für den Filter\n",
    "Die Funktion create_keys nimmt ein Dictionary als Eingabe und gibt eine Zeichenkette zurück, die aus verschiedenen Informationen aus dem Dictionary zusammengesetzt ist. Die Funktion führt folgende Schritte aus:\n",
    "\n",
    "Die Funktion erstellt eine neue Zeichenkette, indem sie den Wert des Schlüssels \"keywords\" des Dictionarys mit Leerzeichen zwischen den einzelnen Keywords verbindet.\n",
    "Die Funktion fügt dann den Wert des Schlüssels \"cast\" des Dictionarys hinzu, indem sie die Namen aller Schauspieler mit Leerzeichen zwischen den Namen verbindet.\n",
    "Die Funktion fügt den Wert des Schlüssels \"director\" des Dictionarys hinzu.\n",
    "Die Funktion fügt schließlich den Wert des Schlüssels \"genres\" des Dictionarys hinzu, indem sie die Namen aller Genres mit Leerzeichen zwischen den Namen verbindet.\n",
    "Die Funktion gibt die zusammengesetzte Zeichenkette schließlich als Rückgabewert zurück."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def create_keys(x):\n",
    "        # Auswahl der Daten welche beachtet werden sollen\n",
    "        return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recommender anhand von ausgewählten Metadaten\n",
    "Die Funktion getCosineMatrixAttributes nimmt zwei DataFrames (metadata und keywords) und ein Dictionary (credits) als Eingabe und gibt eine Matrix zurück. Die Funktion führt folgende Schritte aus:\n",
    "\n",
    "Die Spalte \"id\" in den DataFrames keywords und metadata wird in Integer umgewandelt, indem die astype-Methode verwendet wird. Das Dictionary credits enthält bereits Integer-Werte für die Spalte \"id\".\n",
    "Die DataFrames credits und keywords werden mit dem DataFrame metadata mithilfe der merge-Funktion verbunden, wobei die Spalte \"id\" als gemeinsamen Schlüssel verwendet wird.\n",
    "Die Funktion definiert eine Liste von Features, die für die weitere Verarbeitung verwendet werden sollen: \"cast\", \"crew\", \"keywords\" und \"genres\".\n",
    "Für jedes Feature in der Liste wird der apply-Methodenaufruf verwendet, um die literal_eval-Funktion auf den Wert des Features im DataFrame metadata anzuwenden. Diese Funktion analysiert einen String und gibt eine Liste zurück, wenn der String in Python-Listensyntax gegeben wurde.\n",
    "Ein neues Feature mit dem Namen \"director\" wird im DataFrame metadata erstellt, indem der apply-Methodenaufruf verwendet wird, um die Funktion get_director auf den Wert des Features \"crew\" anzuwenden.\n",
    "Die Funktion definiert erneut eine Liste von Features: \"cast\", \"keywords\" und \"genres\". Für jedes Feature in der Liste wird der apply-Methodenaufruf verwendet, um die Funktion get_list auf den Wert des Features im DataFrame metadata anzuwenden.\n",
    "Die Funktion definiert erneut eine Liste von Features: \"cast\", \"keywords\", \"director\" und \"genres\". Für jedes Feature in der Liste wird der apply-Methodenaufruf verwendet, um die Funktion clean_data auf den Wert des Features im DataFrame metadata anzuwenden.\n",
    "Ein neues Feature mit dem Namen \"keys\" wird im DataFrame metadata erstellt, indem der apply-Methodenaufruf verwendet wird, um die Funktion create_keys auf jede Zeile des DataFrames anzuwenden.\n",
    "Ein CountVectorizer-Objekt wird erstellt und auf das Feature \"keys\" des DataFrames metadata angewendet, um eine Matrix mit Häufigkeitszählungen der einzelnen Wörter zu erhalten."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def getCosineMatrixAttributes(metadata, keywords, credits):\n",
    "    # IDs zu Integers für den merge\n",
    "    keywords['id'] = keywords['id'].astype('int')\n",
    "    credits['id'] = credits['id'].astype('int')\n",
    "    metadata['id'] = metadata['id'].astype('int')\n",
    "\n",
    "    # Merge credits und keywords zu metadata\n",
    "    metadata = metadata.merge(credits, on='id')\n",
    "    metadata = metadata.merge(keywords, on='id')\n",
    "\n",
    "    features = ['cast', 'crew', 'keywords', 'genres']\n",
    "    for feature in features:\n",
    "        metadata[feature] = metadata[feature].apply(literal_eval)\n",
    "\n",
    "    # Zu betrachtende Metadaten\n",
    "    metadata['director'] = metadata['crew'].apply(get_director)\n",
    "\n",
    "    features = ['cast', 'keywords', 'genres']\n",
    "    for feature in features:\n",
    "        metadata[feature] = metadata[feature].apply(get_list)\n",
    "\n",
    "    # clean_data um alles vergleichbar zu machen\n",
    "    features = ['cast', 'keywords', 'director', 'genres']\n",
    "\n",
    "    for feature in features:\n",
    "        metadata[feature] = metadata[feature].apply(clean_data)\n",
    "\n",
    "    # Voher definierte keys\n",
    "    metadata['keys'] = metadata.apply(create_keys, axis=1)\n",
    "\n",
    "    count = CountVectorizer(stop_words='english')\n",
    "    count_matrix = count.fit_transform(metadata['keys'])\n",
    "\n",
    "    return cosine_similarity(count_matrix, count_matrix)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index-Mapping\n",
    "Die Funktion index_mapping ist eine pd.Series-Instanz, die aus der Metadaten-Tabelle erstellt wurde. Die pd.Series enthält den Index jedes Films als Wert und den Titel jedes Films als Index. Dies wird erreicht, indem der Index der Metadaten-Tabelle als Wert und der Titel als Index übergeben wird.\n",
    "\n",
    "Die .drop_duplicates()-Methode wird aufgerufen, um alle Duplikate aus der pd.Series zu entfernen. Wenn mehrere Filme den gleichen Titel haben, wird nur der erste Film in der pd.Series gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIndexMapping (metadata):\n",
    "    # Mappen der Namen auf die IDs und entfernen der Duplikate\n",
    "    index_mapping = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()\n",
    "    return index_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funktion recommend_films\n",
    "Die Funktion recommend_films nimmt den Titel eines Films, eine Zahl n, eine Cosinusähnlichkeitsmatrix und ein Mapping von Filmtiteln auf Matrixindizes sowie einen DataFrame mit Metadaten als Eingabe und gibt eine Liste von empfohlenen Filmtiteln zurück. Die Funktion führt folgende Schritte aus:\n",
    "\n",
    "Der Index des Films mit dem angegebenen Titel wird mithilfe des Mapping-Dictionaries ermittelt.\n",
    "Eine Liste von Tupeln, die den Index und den Cosinusähnlichkeitswert für jeden Film in der Matrix enthalten, wird erstellt.\n",
    "Die Liste wird nach den Cosinusähnlichkeitswerten sortiert, wobei die höchsten Werte zuerst angezeigt werden.\n",
    "Die Liste wird auf die ersten n Einträge gekürzt (außer dem ersten Eintrag, da der Cosinusähnlichkeitswert für den Film selbst immer 1 ist).\n",
    "Eine Liste von Matrixindizes wird aus den Tupeln in der gekürzten Liste erstellt.\n",
    "Die Liste von Filmtiteln wird aus dem DataFrame metadata anhand der Indizes in der Liste von Matrixindizes erstellt und zurückgegeben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "def recommend_films(title, n, cosine_matrix_description, index_mapping, metadata):\n",
    "    index = index_mapping[title]\n",
    "\n",
    "    score = list(enumerate(cosine_matrix_description[index]))\n",
    "\n",
    "    score = sorted(score, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # n + 1 = Anzhal der Filme für den recommender\n",
    "    score = score[1:n + 1]\n",
    "\n",
    "    movie_indices = [i[0] for i in score]\n",
    "\n",
    "    return metadata['title'].iloc[movie_indices]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exemplarische Ausgabe der Empfehlungen (Aufgabe 1)\n",
    "Die oben gezeigte Funktion zeigt Empfehlungen für Filme basierend auf deren Beschreibung und ihren Metadaten an. Die Funktion führt folgende Schritte aus:\n",
    "\n",
    "Ein neuer DataFrame df_metadata wird erstellt, indem einige Zeilen aus dem ursprünglichen DataFrame metadata entfernt werden.\n",
    "Die Cosinusähnlichkeitsmatrix für die Beschreibungen der Filme wird mithilfe der Funktion getCosineMatrixDescription berechnet.\n",
    "Die Cosinusähnlichkeitsmatrix für die Metadaten der Filme wird mithilfe der Funktion getCosineMatrixAttributes berechnet.\n",
    "Ein Mapping von Filmtiteln auf Matrixindizes wird mithilfe der Funktion getIndexMapping erstellt.\n",
    "Die Funktion recommend_films wird aufgerufen, um Empfehlungen für den Film mit dem Titel \"The Dark Knight Rises\" basierend auf der Cosinusähnlichkeitsmatrix für die Beschreibungen und der Cosinusähnlichkeitsmatrix für die Metadaten zu erhalten. Die Empfehlungen werden für die ersten 10 ähnlichen Filme angezeigt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Entfernen von IDs welche fehlerhaft sind\n",
    "df_metadata = metadata.drop([19730, 29503, 35587])\n",
    "\n",
    "title = 'The Dark Knight Rises'\n",
    "cosine_matrix_description = getCosineMatrixDescription(df_metadata)\n",
    "cosine_matrix_attributes = getCosineMatrixAttributes(df_metadata, keywords, credits)\n",
    "index_mapping = getIndexMapping(df_metadata)\n",
    "\n",
    "print('Empfehlungen nach Beschreibung:')\n",
    "# Ausgabe anhand der Beschreibung\n",
    "print(recommend_films(title, 10, cosine_matrix_description, index_mapping, metadata))\n",
    "print('Empfehlungen nach Metadaten:')\n",
    "# Ausgabe anhand der ausgewählten Metadaten\n",
    "print(recommend_films(title, 10, cosine_matrix_attributes, index_mapping, metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Aufgabe 2\n",
    "Im folgenden Abschnitt wird der Aufbau des collaborative Recommenders Schritt für Schritt erläutert. Zum Abschluss werden einige Empfehlungen zu bestimmten Filmen exemplarisch ausgegeben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Neuformartierung Movie Metadata\n",
    "Diese Funktion bereitet einen DataFrame von Filmmetadata auf. Sie nimmt einen DataFrame mit allen Filmmetadata (df_mmeta_local) als Eingabe und gibt einen neuen, formatierten DataFrame (df_movies_local) zurück.\n",
    "Zunächst wird aus dem Release-Datum des Films das Erscheinungsjahr extrahiert und in einer neuen Spalte year im DataFrame gespeichert. Wenn das Release-Datum fehlt oder nicht konvertiert werden kann, wird der Wert NaN verwendet.\n",
    "Anschließend wird die Spalte genres des Eingabedatensatzes extrahiert und auf ihren Inhalt (Liste von Genres) transformiert. Die Spalte genres wird dann in eine Liste von Genrenamen konvertiert.\n",
    "Der Index des DataFrames wird dann auf die Spalte movieId geändert und auf numerische Werte konvertiert.\n",
    "Danach wird die Spalte vote_count aus dem Eingabedatensatz extrahiert und in den neuen DataFrame eingefügt. Der Datentyp von vote_count wird auf Integer konvertiert.\n",
    "Schließlich wird auch der Titel des Films in den neuen DataFrame eingefügt.\n",
    "Der neu formatierte DataFrame wird schließlich zurückgegeben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getDfMovies(df_meta_local):\n",
    "\n",
    "    df_movies_local = pd.DataFrame()\n",
    "    # Extrahieren vom release Jahr\n",
    "    df_movies_local['year'] = pd.to_datetime(df_meta_local['release_date'], errors='coerce').apply(\n",
    "        lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "\n",
    "    # Extrahieren von den Genres\n",
    "    df_movies_local['genres'] = df_meta_local['genres'].fillna('[]').apply(literal_eval).apply(\n",
    "        lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "    # Index zu movieId\n",
    "    df_movies_local['movieId'] = pd.to_numeric(df_meta_local['id'])\n",
    "    df_movies_local = df_movies_local.set_index('movieId')\n",
    "\n",
    "    # Vote_count hinzufügen\n",
    "    df_movies_local['vote_count'] = df_meta_local['vote_count']\n",
    "    df_movies_local['vote_count'] = df_movies_local['vote_count'].astype('int', True, 'ignore')\n",
    "\n",
    "    df_movies_local['title'] = df_meta_local[\"title\"]\n",
    "    return df_movies_local"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trainieren und validieren des Collaborations-Modells\n",
    "Diese Funktion trainiert und validiert ein Collaborative Filtering-Modell für Vorhersage von Bewertungen von Filmen durch Benutzer. Der Code nutzt das Python-Modul Surprise für Collaborative Filtering.\n",
    "Zunächst werden fehlende Werte (NaN) aus dem Eingabedatensatz entfernt. Danach wird der Zeitstempel in der Spalte timestamp in ein datetime-Format konvertiert.\n",
    "Anschließend wird das Reader-Modul von Surprise verwendet, um den Datensatz zu analysieren und in eine Dataset-Instanz zu laden. Der Datensatz enthält Benutzer-ID, Film-ID und Bewertung in Spalten userId, movieId und rating.\n",
    "Der Datensatz wird dann in einen Trainings- und einen Testsatz aufgeteilt. Das Verhältnis wird durch den Wert von test_size festgelegt, in diesem Fall 20%.\n",
    "Danach wird ein SVD-Modell (Singular Value Decomposition) von Surprise instanziiert und mit dem Trainingsdatensatz trainiert.\n",
    "Schließlich wird das trainierte Modell mithilfe der Funktion cross_validate von Surprise validiert. Dabei wird der komplette Datensatz in 10 Fälle aufgeteilt und das Modell 10-fach über alle Fälle validiert. Als Messgrößen werden der Root Mean Squared Error (RMSE), der Mean Absolute Error (MAE) und der Mean Squared Error (MSE) berechnet.\n",
    "Die Funktion gibt schließlich das trainierte und validierte SVD-Modell zurück. Zusätzlich wird ein Balkendiagramm erstellt, das den MAE für jeden Durchlauf der Cross-Validation anzeigt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def trainAndValidateCollaboration(df_ratings_local):\n",
    "\n",
    "    # Entfernen der na-Werte\n",
    "    df_ratings_temp = df_ratings_local.dropna()\n",
    "    # Convertieren der Datetime\n",
    "    df_ratings_temp['timestamp'] = pd.to_datetime(df_ratings_temp['timestamp'], unit='s')\n",
    "\n",
    "    # Parsen von files welche ratings enthalten, ein 'raiting' per Zeile des files\n",
    "    reader = Reader()\n",
    "    ratings_by_users = Dataset.load_from_df(df_ratings_temp[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "    # Trennen von Train-/ und Test-Data\n",
    "    train_df, test_df = train_test_split(ratings_by_users, test_size=.2)\n",
    "\n",
    "    # Trainieren des Models\n",
    "    svd_model = SVD()\n",
    "    svd_model_trained = svd_model.fit(train_df)\n",
    "\n",
    "    # 10-fold Überprüfung\n",
    "    cross_val_results = cross_validate(svd_model_trained, ratings_by_users, measures=['RMSE', 'MAE', 'MSE'], cv=10,\n",
    "                                       verbose=False)\n",
    "    test_mae = cross_val_results['test_mae']\n",
    "\n",
    "    # RMSE-Part\n",
    "    df_test_mae = pd.DataFrame(test_mae, columns=['Root Mean Square Error'])\n",
    "    df_test_mae.index = np.arange(1, len(df_test_mae) + 1)\n",
    "    df_test_mae.sort_values(by='Root Mean Square Error', ascending=False).head(15)\n",
    "\n",
    "    # Plot um RMSE anzuzeigen\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    sns.barplot(y='Root Mean Square Error', x=df_test_mae.index, data=df_test_mae, color=\"b\")\n",
    "    plt.title('Root Mean Square Error')\n",
    "\n",
    "    return svd_model_trained"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Empfehle Filme\n",
    "Diese Funktion empfiehlt Filme für einen gegebenen Benutzer basierend auf Vorhersagen des Bewertungen mithilfe eines Collaborative Filtering-Modells und den von diesem Benutzer bereits bewerteten Filmen.\n",
    "Zunächst wird der gewählte Film angezeigt, indem der DataFrame df_movies_local nach dem angegebenen Titel durchsucht wird. Der Film wird dann anhand seines Erscheinungsjahrs gefiltert und der DataFrame df_movies_local wird auf Filme aus dem gleichen Jahr beschränkt.\n",
    "Danach wird der DataFrame df_ratings nach Bewertungen des angegebenen Benutzers gefiltert und die Anzahl der Bewertungen wird ausgegeben.\n",
    "Schließlich wird für jeden Film in df_movies_local eine Vorhersage der Bewertung durch den Benutzer mithilfe des übergebenen, trainierten Collaborative Filtering-Modells berechnet. Die Vorhersagen werden in einem DataFrame df_recommendations zusammengefasst, der die Filme mit ihren vorhergesagten und tatsächlichen Bewertungen enthält. Schließlich wird der DataFrame sortiert und die empfohlenen Filme werden anhand der vorhergesagten Bewertungen absteigend angezeigt. Die Anzahl der empfohlenen Filme wird durch den Wert von n festgelegt."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def recommend_films_by_collaboration(title, n, user_id, svd_model_trained, df_movies_local, df_ratings):\n",
    "\n",
    "    chosenMovie = df_movies_local[df_movies_local['title'] == title]\n",
    "    year = chosenMovie[\"year\"].iloc[0]\n",
    "\n",
    "    # Filter nach Jahr\n",
    "    df_movies_local = df_movies_local[df_movies_local['year'] == year]\n",
    "\n",
    "    df_ratings_filtered = df_ratings[df_ratings['userId'] == user_id]\n",
    "\n",
    "    pred_series = []\n",
    "    for movie_id, name in zip(df_movies_local.index, df_movies_local['title']):\n",
    "        rating_pred = svd_model_trained.predict(user_id, movie_id, 0, verbose=False)\n",
    "        pred_series.append([movie_id, name, rating_pred.est, 0])\n",
    "    df_recommendations = pd.DataFrame(pred_series, columns=['movieId', 'title', 'predicted_rating', 'actual_rating'])\n",
    "    display(df_recommendations.sort_values(by='predicted_rating', ascending=False).head(n))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exemplarische Ausgabe der Empfehlungen (Aufgabe 2)\n",
    "Dieser Code empfiehlt Filme für einen gegebenen Benutzer anhand von Vorhersagen mithilfe von Collaborative Filtering.\n",
    "\n",
    "Zunächst wird der DataFrame mit Filmmetadaten mithilfe der Funktion getDfMovies aufbereitet und in der Variablen df_movies gespeichert. Anschließend wird ein Collaborative Filtering-Modell mithilfe der Funktion trainAndValidateCollaboration trainiert und in der Variablen svd_model_trained gespeichert.\n",
    "Danach werden die Variablen title, user_id und n definiert, die den Titel des zu empfehlenden Films, die Benutzer-ID des Benutzers und die Anzahl der empfohlenen Filme angeben.\n",
    "Schließlich wird die Funktion recommend_films_by_collaboration aufgerufen und die Variablen title, n, user_id, svd_model_trained und df_movies werden als Argumente übergeben. Die Funktion empfiehlt Filme für den gegebenen Benutzer und gibt eine Liste von empfohlenen Filmen aus, sortiert nach ihren vorhergesagten Bewertungen."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Entfernen von IDs welche fehlerhaft sind\n",
    "df_meta = metadata.drop([19730, 29503, 35587])\n",
    "\n",
    "df_movies = getDfMovies(df_meta)\n",
    "svd_model_trained = trainAndValidateCollaboration(rating)\n",
    "\n",
    "title = 'The Dark Knight Rises'\n",
    "user_id = 400\n",
    "n = 10\n",
    "\n",
    "# Ausgabe anhand vom collaborativen Filter\n",
    "recommend_films_by_collaboration(title, n, user_id, svd_model_trained, df_movies, rating)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
